### Chapter11.规模化微服务

#### 11.1.故障无处不在

+ 网络是不可靠的，对于分布式系统而言，故障无可避免。与其试图阻止不可避免的故障上少花一点时间，还不如花多点时间优雅地处理它。

#### 11.2.多少是太多

+ 跨功能需求需要考虑，数据的持久性，服务的可用性，吞吐量和服务可接受的延迟等这些方面。

了解你可以容忍多少故障，或者系统需要多快，取决于系统的用户。可以从这几方面进行考虑：

1. 响应时间/延迟：各种操作需要多长时间？我们可以使用不同数量的用户来测量它，以了解负载的增加会对响应时间造成什么样的影响。
2. 可用性：你能接受服务出现故障吗？可接受的停机的时间是多少？
3. 数据持久性：多大比例的数据丢失是可以接受的？数据应该保存多久？

#### 11.3.功能降级

没什么好说的。构建一个弹性系统，尤其是当功能分散在多个不同的，有可能宕掉的微服务上时，重要的是能够安全地降级功能。

#### 11.4.架构性安全措施

有一些模式，组合起来被称为**架构性安全措施**，它们可以确保如果事情真的出错了，不会引起严重的级联影响。

#### 11.5.反脆弱的组织

比如：在一天的特定时段随机停掉服务器或机器。通过让软件拥抱和引发故障，并构建系统来应对。

##### 11.5.1.超时

超时是很容易被忽视的事情，但在使用下游系统时，正确地处理它是很重要的。在考虑下游系统确实已经宕掉之前，我需要等待多长时间？

如果等待太长时间来决定调用失败，整个系统会被拖慢。如果超时太短，你会将一个可能还在正常工作的调用错认为是失败的。如果完全没有超，一个宕掉的下游系统可能会让整个系统挂起。

给所有的跨进程调用设置超时，并选择一个默认的超时时间。当超时发生后，记录到日志里看看发生了什么，并相应地调整它们。

##### 11.5.2.断路器

使用断路器时，当对下游资源的请求发生一定数量的失败后，断路器会打开。接下来，所有的请求在断路器打开的状态下，会快速地失败。一段时间后，客户端发送一些请求查看下游服务是否已经恢复，如果它得到了正常的响应，将重置断路器。（也就是**快速拒绝**，错误量限频等）

当断路器断开后，你有一些选项。其中之一是堆积请求，然后稍后重试它们。对于一些场景，这可能是合适的，特别是你所做的工作是异步作业的一部分时。然而，如果这个调用作为同步调用链的一部分，快速失败可能更合适。这意味着，沿调用链向上传播错误，或更微妙的降级功能。

##### 11.5.3.舱壁

**舱壁**，是把自己从故障中隔开的一种方式。

关注点分离也是实现舱壁的一种方式。通过把功能分离成独立的微服务，减少了因为一个功能的宕机而影响另一个的可能性。

看看你的系统所有可能出错的方面，无论是微服务内部还是微服务之间。你手头有舱壁可以使用吗？我建议，至少为每个下游连接建立一个单独的连接池。不过，你可能想要更进一步，也考虑使用断路器。

####11.6.幂等

对**幂等**操作来说，其多次执行所产生的影响，均与一次执行的影响相同。如果操作是幂等的，我们可以对其重复多次调用，而不必担心会有不利影响。当我们不确定操作是否被执行，想要重新处理消息，从而从错误中恢复时，幂等会非常有用。

#### 11.7.扩展

让我们看一些常见的通用扩展技术，并思考如何将它们应用于微服务架构中。

##### 11.7.1.更强大的主机

一些操作可能受益于更强大的主机。一个有着更快的CPU和更好的I/O的机器，通常可以改善延迟和吞吐量，允许你在更短的时间内处理更多的工作。这种形式的扩展通常被称为**垂直扩展**。

##### 11.7.2.拆分负载

单服务单主机模型肯定要优于多服务单主机模型。然而在最初的时候，很多人决定将多个微服务共存于一台主机，以降低成本或简化主机管理。因为微服务是通过网络通信的独立进程，所以把它们切换到使用自己的主机来提高吞吐量和伸缩性，应该是一件很容易的事。这还可以增加系统的弹性，因为单台主机的宕机将影响较少数量的微服务。

当然，我们也可能因为要扩展需要把现有的微服务拆分成几个部分，以更好地处理负载。（读写分离，快慢分离等）。

##### 11.7.3.分散风险

弹性扩展的一种方式是，确保不要把所有的鸡蛋放在一个篮子里。一个简单的例子是，确保你不要把多个服务放到一台主机上，因为主机的宕机会影响多个服务。一些虚拟化平台能够确保你的主机分布在多个不同的物理机上，以减少发生上述情况的可能性。

另一种常见的减少故障的方法是，确保不要让所有的服务都运行在同一个数据中心的同一个机架上，而是分布在多个数据中心。如果你使用基础服务供应商，知道SLA（服务等级协议）是否提供和具备相应的计划是非常重要的。

##### 11.7.4.负载均衡

当你想让服务具有弹性时，要避免单点故障。对于公开一个同步HTTP接口这样典型的微服务来说，要达到这个目的最简单的方法是，在一个负载均衡器后，放置多台主机运行你的微服务实例。对于微服务的消费者来说，你不知道你是在跟一个微服务实例通信，还是一百个。

负载均衡器各种各样，从大型昂贵的硬件设备，到像mod_proxy这样基于软件的负载均衡器。它们都有一些共同的关键功能。它们都是基于一些算法，将调用分发到一个或多个实例中，当实例不再健康时移除它们，并当它们恢复健康后再添加进来。

一些负载均衡器提供了其他有用的功能。常见的一个是SSL终止，通过HTTPS连接如站负载均衡器后，当到实例本身时转换成HTTP连接。（如Nginx7层负载均衡）。

##### 11.7.5.基于worker的系统

负载均衡不是服务的多个实例分担负载和降低脆弱性的唯一方式。根据操作性质的不同，基于worker的系统可能和负载均衡一样有效。在这里，所有的实例工作在一些共享的待办作业列表上。

该模型同样适用于负载高峰，你可以按需增加额外的实例来处理更多的负载。只要作业队列本身具有弹性，该模型就可以用于改善作业的吞吐量，也可以改善其弹性，因为它很容易应对worker故障（或worker不存在）带来的影响。作业有可能需要更长的时间，但不会丢失。

使用基于worker系统时，虽然worker本身不需要很高的可靠性，但保存待办作业列表的系统时需要。你可以使用一个持久化的**消息代理**来解决这个问题，或使用像Zookeeper这样的系统。

##### 11.7.6.重新设计

产品的初期不建议对系统进行重新设计。直到容量达到瓶颈时，才选择重新设计。

#### 11.8.扩展数据库

扩展无状态的微服务的是相对简单的。但如果我们把数据存储在一个数据库呢？我们也需要知道如何扩展数据库。

##### 11.8.1.服务的可用性和数据的持久性

##### 11.8.2.扩展读取

在像MySQL或Postgres这样的RDBMS（关系型数据库管理系统）中，数据可以从主节点复制到一个或多个副本。这样做通常是为了确保有一份数据的备份以保证安全，但我们也可以用它来分发读取。服务可以在单个节点上进行所有的写操作，但是读取被分发到一个或多个只读副本。从主数据库复制到副本，是在写入后的某个时刻完成的，这意味着使用这种技术读取，有时候看到的可能是失效的数据，但是最终能够读取到一致的数据，这样的方式被称为最终一致性。

##### 11.8.3.扩展写操作

扩展读取时比较容易的。那么扩展写操作呢？一种方法是使用分片。采用分片方式，会存在多个数据库节点。当你有一块数据要写入时，对数据的关键字应用一个哈希函数，并基于这个函数的结果决定将数据发送到哪个分片。（例如：用户路由，商户路由写入单据）

分片写操作的复杂性来自于查询处理。查找单个记录是很容易的，因为可以应用哈希函数找到数据应该在哪个实例上，然后从正确的分片获取它。但是如果查询跨越了多个节点呢？需要查询所有的分片，要么需要查询每个分片，然后在内存里进行拼接，要么有一个替代的读数据库包含所有的数据集。跨分片查询往往采用异步机制。

使用分片系统会出现的问题之一是，如果我想添加一个额外的数据库节点该怎么办？在过去，这往往需要大量的宕机时间（特别是对于大型集群），这里的操作处理会比较繁琐。

而且，写入分片可能会扩展写容量，但不会提高弹性。如果客户记录A-M总是去实例X，那么当实例X不可用时，A-M的记录依然无法访问。

##### 11.8.4.共享数据库基础设施

**CQRS**：命令查询职责分离模式，是一个存储和查询信息的替代模型，读写分离。（如大单和商户平台pgxz的关系）；



#### 11.9.缓存

##### 11.9.1.客户端，代理和服务器端缓存

**客户端缓存**：客户端会存储缓存的结果。由客户端决定何时（以及是否）获取最新副本。理想情况下，下游服务将提供相应的提示，以帮助客户端了解如何处理响应，因此客户端知道何时以及是否需要发送一个新的请求。

客户端缓存可以大大减少网络调用的次数，并且是减少下游服务负载的最快方法之一。但是使用由客户端负责缓存这种方式，如果你想改变缓存的方式，让大批的消费者全都变化是很困难的。让过时的数据失效也比较棘手。

**代理服务器缓存**：是将一个代理服务器放在客户端和服务器之间，反向代理或CDN（内容分发网络），是很好的使用代理服务器缓存的例子。

使用代理服务器缓存时，一切对客户端和服务器都是不透明的。这通常是增加缓存到现有系统的一个非常简单的方法。如果代理服务器被设计成对通用的流量进行缓存，它也可以缓存多个服务。一个常见的例子是，反向代理 Squid 或 Varnish，它们可以缓存任何 HTTP 通信。在客户端和服务器间加入代理服务器，会引入额外的网络跳数，虽然以我的经验来说，它很少会导致出现问题，因为缓存本身的性能优化意见超过了其他额外的网络开销。

**服务器端缓存**：是由服务器来负责处理缓存，可能会使用像 Redis 或 Memcache 这样的系统，也可能是一个简单的内存缓存。

使用服务器缓存，一切对客户端都是不透明的，它们不需要关心任何事情。缓存在服务器外围或服务器限界内时，很容易了解一些类似数据是否失效这样的事情，还可以跟踪和优化缓存命中率。在你有多种类型客户端的情况下，服务器缓存可能是提高性能的最快方式。

**做系统而言，应该最终混合使用这三种方法。**



##### 11.9.2.HTTP缓存

指令列表：cache-control，Expires，ETag



##### 11.9.3.为写使用缓存

**对于写入请求，先写入本地缓存，返回前端成功，再异步去写下游数据源。（有一定的风险）**

如果你使用后写式缓存，可以先写入本地缓存中，并在之后的某个时刻将缓存中的数据写入下游，可能更规范化的数据源中。当你有爆发式的写操作，或同样的数据可能被写入多次时，这是很有用的，后写式缓存是在缓冲可能的批处理写操作时，进一步优化性能的很有用的方法。

使用后写式缓存，如果对写操作的缓冲做了适当的持久化，那么即使下游服务不可用，我们也可以将写操作放到队列里，然后当下游服务可用时再将它们发送过去。



##### 11.9.4.为弹性使用缓存

缓存可以在出现故障时实现弹性。使用客户端缓存，如果下游服务不可用，客户端可以先简单地使用缓存中可能失效了的数据。我们还可以使用像反向代理这样的系统提供的失效数据。对一些系统来说，使用失效但可用的数据，比完全不可用的要好，不过这需要你自己做出判断。



##### 11.9.5.隐藏源服务

使用普通的缓存，如果请求缓存失败，请求会继续从数据源获取最新的数据，请求会继续从数据源获取最新的数据，请求调用会一直等到结果返回。在普通情况下，这是期望的行为。但是，如果遭受大量请求缓存失败，也许是因为提供缓存的整个机器（或一组机器）宕掉，大量的请求会被发送到源服务，担心会因此击穿源服务。

在这种情况下，保护源服务的一种方式是，在第一时间就不要对源服务发起请求。相反，在需要时源服务本身会异步地填充缓存。如果缓存请求失败，会触发一个给源服务的事件，提醒它需要重新填充缓存。所以如果整个分片消失了，我们可以在后台重建缓存。可以阻塞请求直到区域被重新填充，但这可能会使缓存本身的争用，从而导致一些问题。更合适的是，如果想优先保持系统的稳定，我们可以让原始请求失败，但要快速地失败。



##### 11.9.6.保持简单

避免在太多地方使用缓存！在你和数据源之间的缓存越多，数据就越可能失效，就越难确定客户端最终看到的是否是最新的数据。这在一个涉及多个服务的微服务架构调用链中，很有可能产生问题。再强调一次，缓存越多，越难评估任何数据的新鲜程度。所以如果你认为缓存是一个好主意，请保持简单，先在一处使用缓存，在添加更多的缓存前慎重考虑！



##### 11.9.7.缓存中毒

永远使用的失效的缓存数据，称为缓存中毒。



#### 11.10.自动伸缩

如果你足够幸运，可以完全自动化地创建虚拟主机以及部署你的微服务实例，那么你已经具备了对微服务进行自动伸缩的基本条件。自动伸缩主要分为：**响应型伸缩**和**预测型伸缩**。



#### 11.11.CAP定理

C(consistency)：一致性；

A(availability)：可用性；

P(partition tolerance)：分区容忍性。

对于分布式系统，是不能不存在跨网络运行的，需要所有的东西都在本地的一个单独进程里运行是不现实的。因此，CA系统在分布式系统中根本是不存在的。

要么AP，要么CP。



#### 11.12.服务发现

一旦你已经拥有了不少微服务，关注点就会不可避免地转向它们究竟在何处。也许你想知道，在特定环境下有哪些微服务在运行，据此你才能知道哪些应该被监测。从广义上来说，上述所有用例都属于服务发现。

让我们看一些最常见的服务发现解决方案，然后再考虑如何选择。

**DNS**：最好先从简单的开始。DNS让我们将一个名称与一个或多个机器的IP地址相关联。



#### 11.13.动态服务注册

作为一种在高度动态的环境发现节点的方法，DNS存在一些缺点，从而催生了大量的替代系统，其中大部分包括服务注册和一些集中的注册表，注册表进而可以提供查找这些服务的能力。通常，这些系统所做的不仅仅是服务注册和服务发现，这可能也不是一件好事。这是一个拥挤的领域，因此只看其中几个选项，让你大概了解一下有哪些选择可用。

##### 11.13.1.Zookeeper

##### 11.13.2.Consul

##### 11.13.3.Eureka

##### 11.13.4.构建你自己的系统

##### 11.13.5.别忘了上面这些系统的使用要考虑人的因素



#### 11.14.文档服务

通过将系统分解更细粒度的微服务，我们希望以API的形式暴露出很多接缝，人们可以用它来做很多很棒的事情。如果正确地进行了服务发现，就能够知道东西在哪里。但是我们如何知道这些东西的用处，或如何使用它们？一个明显的选择是API的文档。当然，文档往往会过时。理想情况下，我们会确保文档总是和最新的微服务API同步，并当大家需要知道服务在哪里时，能够很容易地看到这个文档。两种不同的技术，**Swagger**和**HAL**。



#### 11.15.自描述系统

在SOA的早期演化过程中，UDDI（通用描述，发现与集成服务）标准的出现，帮助人们理解了哪些服务正在运行。这些方法都相当重量级，并催生出一些替代技术去试图理解我们的系统。









